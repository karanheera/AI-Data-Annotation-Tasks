{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e287a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 annotation items.\n",
      "✅ Taxonomy annotation analysis complete. Results saved in 'results/' folder.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# ============================================================\n",
    "# Paths\n",
    "# ============================================================\n",
    "DATA_FILE = \"../annotations/train.json\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "Path(RESULTS_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# Load Data\n",
    "# ============================================================\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(data)} annotation items.\")\n",
    "\n",
    "# ============================================================\n",
    "# Extract Texts and Taxonomy Labels\n",
    "# ============================================================\n",
    "texts = []\n",
    "level1_labels = []\n",
    "level2_labels = []\n",
    "annotated_flags = []\n",
    "\n",
    "for item in data:\n",
    "    text = item.get(\"data\", {}).get(\"text\")\n",
    "    ann_list = item.get(\"annotations\", [])\n",
    "    level1 = level2 = None\n",
    "    is_annotated = False\n",
    "    \n",
    "    if ann_list:\n",
    "        res_list = ann_list[0].get(\"result\", [])\n",
    "        if res_list:\n",
    "            taxonomy = res_list[0].get(\"value\", {}).get(\"taxonomy\", [])\n",
    "            if taxonomy and isinstance(taxonomy[0], list):\n",
    "                is_annotated = True\n",
    "                level1 = taxonomy[0][0] if len(taxonomy[0]) > 0 else None\n",
    "                level2 = taxonomy[0][1] if len(taxonomy[0]) > 1 else None\n",
    "\n",
    "    texts.append(text)\n",
    "    level1_labels.append(level1)\n",
    "    level2_labels.append(level2)\n",
    "    annotated_flags.append(is_annotated)\n",
    "\n",
    "# ============================================================\n",
    "# Annotation Statistics\n",
    "# ============================================================\n",
    "total_annotations = len(texts)\n",
    "level1_counts = Counter([l for l in level1_labels if l])\n",
    "level2_counts = Counter([l for l in level2_labels if l])\n",
    "\n",
    "missing_labels = sum(1 for l in level1_labels if not l)\n",
    "missing_texts = sum(1 for t in texts if not t)\n",
    "duplicate_texts = len(texts) - len(set(t for t in texts if t))\n",
    "incomplete_annotations = sum(1 for a in annotated_flags if not a)\n",
    "\n",
    "# Text length stats\n",
    "text_lengths = [len(t.split()) for t in texts if t]\n",
    "if text_lengths:\n",
    "    min_len = min(text_lengths)\n",
    "    max_len = max(text_lengths)\n",
    "    avg_len = sum(text_lengths) / len(text_lengths)\n",
    "else:\n",
    "    min_len = max_len = avg_len = 0\n",
    "\n",
    "# ============================================================\n",
    "# Extra 1: Imbalance Ratio\n",
    "# ============================================================\n",
    "max_count = max(level1_counts.values()) if level1_counts else 1\n",
    "imbalance_ratio = {label: round(count / max_count, 2) for label, count in level1_counts.items()}\n",
    "\n",
    "# ============================================================\n",
    "# Extra 2: Taxonomy Consistency Check\n",
    "# (Define expected parent-child structure for validation)\n",
    "# ============================================================\n",
    "expected_map = {\n",
    "    \"Sports\": [\"Basketball\", \"Football\", \"Cricket\", \"Tennis\"],\n",
    "    \"Entertainment\": [\"Movies\", \"Music\", \"TV Shows\", \"Celebrities\"],\n",
    "    \"Technology\": [\"AI\", \"Gadgets\", \"Software\", \"Hardware\"]\n",
    "}\n",
    "\n",
    "inconsistent_pairs = []\n",
    "for l1, l2 in zip(level1_labels, level2_labels):\n",
    "    if l1 and l2 and l1 in expected_map:\n",
    "        if l2 not in expected_map[l1]:\n",
    "            inconsistent_pairs.append((l1, l2))\n",
    "\n",
    "# ============================================================\n",
    "# Extra 3: Completeness (unannotated tasks)\n",
    "# ============================================================\n",
    "annotation_completeness = 100 * (1 - incomplete_annotations / total_annotations)\n",
    "\n",
    "# ============================================================\n",
    "# Save annotations_stats.txt\n",
    "# ============================================================\n",
    "with open(f\"{RESULTS_DIR}/annotations_stats.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Total annotations: {total_annotations}\\n\\n\")\n",
    "    f.write(\"Level 1 Taxonomy Counts:\\n\")\n",
    "    for label, count in level1_counts.items():\n",
    "        f.write(f\"- {label}: {count}\\n\")\n",
    "    f.write(\"\\nLevel 2 Taxonomy Counts:\\n\")\n",
    "    for label, count in level2_counts.items():\n",
    "        f.write(f\"- {label}: {count}\\n\")\n",
    "    f.write(f\"\\nMissing taxonomy labels: {missing_labels}\\n\")\n",
    "    f.write(f\"Incomplete annotations: {incomplete_annotations}\\n\")\n",
    "    f.write(f\"Annotation completeness: {annotation_completeness:.2f}%\\n\")\n",
    "    f.write(f\"Missing texts: {missing_texts}\\n\")\n",
    "    f.write(f\"Duplicate texts: {duplicate_texts}\\n\")\n",
    "    f.write(f\"Text length (words) - min: {min_len}, max: {max_len}, avg: {avg_len:.2f}\\n\\n\")\n",
    "    f.write(\"Imbalance Ratio (vs. largest class):\\n\")\n",
    "    for label, ratio in imbalance_ratio.items():\n",
    "        f.write(f\"- {label}: {ratio}\\n\")\n",
    "    f.write(\"\\nInconsistent taxonomy pairs:\\n\")\n",
    "    for l1, l2 in inconsistent_pairs:\n",
    "        f.write(f\"- {l1} → {l2}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# Save eval_summary.txt\n",
    "# ============================================================\n",
    "with open(f\"{RESULTS_DIR}/eval_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Evaluation Summary (Taxonomy Annotations)\\n\")\n",
    "    f.write(\"-------------------------------------------\\n\")\n",
    "    f.write(f\"Total annotations: {total_annotations}\\n\")\n",
    "    f.write(f\"Incomplete annotations: {incomplete_annotations}\\n\")\n",
    "    f.write(f\"Annotation completeness: {annotation_completeness:.2f}%\\n\")\n",
    "    f.write(f\"Missing taxonomy labels: {missing_labels}\\n\")\n",
    "    f.write(f\"Missing texts: {missing_texts}\\n\")\n",
    "    f.write(f\"Duplicate texts: {duplicate_texts}\\n\")\n",
    "    f.write(f\"Inconsistent taxonomy pairs: {len(inconsistent_pairs)}\\n\")\n",
    "    f.write(f\"Text length (words) - min: {min_len}, max: {max_len}, avg: {avg_len:.2f}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# Generate Bar Charts\n",
    "# ============================================================\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(level1_counts.keys(), level1_counts.values(), color=\"skyblue\")\n",
    "plt.title(\"Level 1 Taxonomy Distribution\")\n",
    "plt.xlabel(\"Level 1 Categories\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/level1_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "if level2_counts:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(level2_counts.keys(), level2_counts.values(), color=\"lightgreen\")\n",
    "    plt.title(\"Level 2 Taxonomy Distribution\")\n",
    "    plt.xlabel(\"Level 2 Categories\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/level2_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# Generate report.md\n",
    "# ============================================================\n",
    "with open(f\"{RESULTS_DIR}/report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# Taxonomy Annotation Report\\n\\n\")\n",
    "    f.write(f\"Total annotations: **{total_annotations}**\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Level 1 Taxonomy Counts\\n\")\n",
    "    for label, count in level1_counts.items():\n",
    "        f.write(f\"- **{label}**: {count}\\n\")\n",
    "\n",
    "    f.write(\"\\n## Level 2 Taxonomy Counts\\n\")\n",
    "    for label, count in level2_counts.items():\n",
    "        f.write(f\"- **{label}**: {count}\\n\")\n",
    "\n",
    "    f.write(f\"\\n## Missing taxonomy labels: {missing_labels}\\n\")\n",
    "    f.write(f\"## Incomplete annotations: {incomplete_annotations}\\n\")\n",
    "    f.write(f\"## Annotation completeness: {annotation_completeness:.2f}%\\n\")\n",
    "    f.write(f\"## Missing texts: {missing_texts}\\n\")\n",
    "    f.write(f\"## Duplicate texts: {duplicate_texts}\\n\")\n",
    "    f.write(f\"## Inconsistent taxonomy pairs: {len(inconsistent_pairs)}\\n\")\n",
    "    f.write(f\"## Text Length Stats (words) - min: {min_len}, max: {max_len}, avg: {avg_len:.2f}\\n\")\n",
    "\n",
    "    f.write(\"\\n## Imbalance Ratio (vs. largest class)\\n\")\n",
    "    for label, ratio in imbalance_ratio.items():\n",
    "        f.write(f\"- {label}: {ratio}\\n\")\n",
    "\n",
    "    if inconsistent_pairs:\n",
    "        f.write(\"\\n## Inconsistent Taxonomy Pairs Found\\n\")\n",
    "        for l1, l2 in inconsistent_pairs[:10]:\n",
    "            f.write(f\"- {l1} → {l2}\\n\")\n",
    "        if len(inconsistent_pairs) > 10:\n",
    "            f.write(f\"...and {len(inconsistent_pairs)-10} more\\n\")\n",
    "\n",
    "    # Random sample texts by Level 1 category\n",
    "    f.write(\"\\n## Random Sample Texts by Level 1 Category\\n\")\n",
    "    for label in level1_counts.keys():\n",
    "        samples = [t for t, l in zip(texts, level1_labels) if l == label and t]\n",
    "        if samples:\n",
    "            f.write(f\"\\n### {label}\\n\")\n",
    "            for txt in random.sample(samples, min(5, len(samples))):\n",
    "                f.write(f\"- {txt}\\n\")\n",
    "\n",
    "    # Add plots\n",
    "    f.write(\"\\n## Taxonomy Distribution Plots\\n\")\n",
    "    f.write(\"![Level 1 Taxonomy Distribution](level1_distribution.png)\\n\")\n",
    "    if level2_counts:\n",
    "        f.write(\"![Level 2 Taxonomy Distribution](level2_distribution.png)\\n\")\n",
    "\n",
    "print(\"✅ Taxonomy annotation analysis complete. Results saved in 'results/' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
